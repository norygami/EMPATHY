{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert Dataset (jsonl) -> fine-tune dolphin-mistal-7b -> quantize -> create ollama Modelfile -> push .gguf (HF)\n",
    "\n",
    "TODO:\n",
    "- Convert .ipynb to py\n",
    "  - dataset.py | train.py\n",
    "- Create config.yaml\n",
    "  - Base Model + Dataset\n",
    "  - Training parameters\n",
    "  - Quantization Methods\n",
    "- Check Discord implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from random import shuffle, seed\n",
    "\n",
    "def convert_to_jsonl(input_directory, \n",
    "                     output_dir, \n",
    "                     split_ratio=0.8, \n",
    "                     random_seed=42):\n",
    "\n",
    "    seed(random_seed)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    train_filename = os.path.join(output_dir, 'train.jsonl')\n",
    "    eval_filename = os.path.join(output_dir, 'eval.jsonl')\n",
    "\n",
    "    # Clear existing data in output files\n",
    "    open(train_filename, 'w').close()\n",
    "    open(eval_filename, 'w').close()\n",
    "\n",
    "    for input_filename in os.listdir(input_directory):\n",
    "        if input_filename.endswith('.txt'):\n",
    "            bot_name = input_filename[:-4]\n",
    "            file_path = os.path.join(input_directory, input_filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                conversation_blocks = file.read().split('\\n\\n')\n",
    "                shuffle(conversation_blocks)  # Shuffle for random splitting\n",
    "                split_index = int(len(conversation_blocks) * split_ratio)\n",
    "\n",
    "            train_chats = []\n",
    "            eval_chats = []\n",
    "\n",
    "            for block in conversation_blocks[:split_index]:\n",
    "                train_chats.extend(extract_chats(block, bot_name))\n",
    "\n",
    "            for block in conversation_blocks[split_index:]:\n",
    "                eval_chats.extend(extract_chats(block, bot_name))\n",
    "\n",
    "            # Write to train and eval files\n",
    "            write_jsonl(train_chats, train_filename)\n",
    "            write_jsonl(eval_chats, eval_filename)\n",
    "\n",
    "def extract_chats(block, bot_name):\n",
    "    lines = block.split('\\n')\n",
    "    chat = [{\"role\": \"system\", \"content\": bot_name}]\n",
    "    for line in lines:\n",
    "        if line.startswith(\"HUMAN:\"):\n",
    "            chat.append({\"role\": \"user\", \"content\": line.replace(\"HUMAN:\", \"\").strip()})\n",
    "        elif line.startswith(\"RESPONSE:\"):\n",
    "            chat.append({\"role\": \"assistant\", \"content\": line.replace(\"RESPONSE:\", \"\").strip()})\n",
    "\n",
    "    return [{\"chat\": chat}] if len(chat) > 1 else []\n",
    "\n",
    "def write_jsonl(chats, filename):\n",
    "    with open(filename, 'a', encoding='utf-8') as jsonl_file:\n",
    "        for chat in chats:\n",
    "            json.dump(chat, jsonl_file)\n",
    "            jsonl_file.write('\\n')\n",
    "\n",
    "# Configuration\n",
    "base_dir = os.getcwd()\n",
    "repo_dir = 'datasets/TRACHI'\n",
    "input_directory = os.path.join(base_dir, 'datasets', 'raw')\n",
    "output_dir = os.path.join(base_dir, repo_dir)\n",
    "\n",
    "# Convert txt files to jsonl files with splitting\n",
    "convert_to_jsonl(input_directory, output_dir)\n",
    "\n",
    "dataset = load_dataset(repo_dir)\n",
    "dataset.push_to_hub(\"norygano/TRACHI\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
